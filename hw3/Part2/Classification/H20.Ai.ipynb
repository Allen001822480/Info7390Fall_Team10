{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "# from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "#from Part2_get_data import get_data\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from collections import OrderedDict\n",
    "from multiprocessing import Process, Lock, Manager\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global df1\n",
    "global df2\n",
    "#historical_data1_time_Q12006\n",
    "col_names_svcg = ['loan_sequence_no', 'monthly_reporting_period', 'current_actual_upb', 'current_loan_delinquency_status',\n",
    "                  'loan_age', 'remaning_months_on_legal_maturity', 'repurchase_flag', 'modification_flag', 'zero_bal_code',\n",
    "                  'zero_bal_eff_date', 'current_interest_rate', 'current_deferred_upb', 'ddlpi', 'mi_recoveries', 'net_sales_proceeds',\n",
    "                  'non_mi_recoveries', 'expenses', 'legal_costs', 'maintenance_preservation_cost', 'taxes_insurance', 'misc_expenses',\n",
    "                  'actual_loss_calc', 'modification_cost']\n",
    "\n",
    "df1 = pd.read_table('HistoricalInputFiles/historical_data1_time_Q12006.txt',\n",
    "                    delimiter='|', names=col_names_svcg, index_col=None, nrows=200000, low_memory=False, usecols=list(np.arange(23)))\n",
    "df2 = pd.read_table('HistoricalInputFiles/historical_data1_time_Q22006.txt',\n",
    "                    delimiter='|', names=col_names_svcg, index_col=None, nrows=200000, low_memory=False, usecols=list(np.arange(23)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global X_train\n",
    "global y_train\n",
    "global X_test\n",
    "global y_test\n",
    "global matrix\n",
    "global conf_mat_logred\n",
    "global conf_mat_rf\n",
    "global conf_mat_nn\n",
    "global roc_auc_logred\n",
    "global roc_auc_rf\n",
    "global roc_auc_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan(dff):\n",
    "    dff.current_loan_delinquency_status = dff.current_loan_delinquency_status.replace('R', '1').astype('float64')\n",
    "\n",
    "    dff.remaning_months_on_legal_maturity = dff.remaning_months_on_legal_maturity.replace(np.nan, 0)\n",
    "    dff.remaning_months_on_legal_maturity = dff.remaning_months_on_legal_maturity.astype('category')\n",
    "\n",
    "    dff.repurchase_flag = dff.repurchase_flag.replace(np.nan, 0)\n",
    "    dff.repurchase_flag = dff.repurchase_flag.astype('category')\n",
    "\n",
    "    dff.modification_flag = dff.modification_flag.replace(np.nan, 0)\n",
    "    dff.modification_flag = dff.modification_flag.astype('category')\n",
    "\n",
    "    dff.zero_bal_code = dff.zero_bal_code.replace(np.nan, 0)\n",
    "    dff.zero_bal_code = dff.zero_bal_code.astype('category')\n",
    "\n",
    "    dff.zero_bal_eff_date = dff.zero_bal_eff_date.replace(np.nan, 0)\n",
    "    dff.zero_bal_eff_date = dff.zero_bal_eff_date.astype('category')\n",
    "\n",
    "    dff.current_deferred_upb = dff.current_deferred_upb.replace(np.nan, 0)\n",
    "    dff.current_deferred_upb = dff.current_deferred_upb.astype('category')\n",
    "\n",
    "    dff.ddlpi = dff.ddlpi.replace(np.nan, 0)\n",
    "    dff.ddlpi = dff.ddlpi.astype('category')\n",
    "\n",
    "    dff.mi_recoveries = dff.mi_recoveries.replace(np.nan, 0)\n",
    "\n",
    "    dff.net_sales_proceeds = dff.net_sales_proceeds.replace(np.nan, 0)\n",
    "    dff.net_sales_proceeds = dff.net_sales_proceeds.replace('C', 1)\n",
    "    dff.net_sales_proceeds = dff.net_sales_proceeds.replace('U', 0)\n",
    "    dff.net_sales_proceeds.astype('float64')\n",
    "\n",
    "    dff.non_mi_recoveries = dff.non_mi_recoveries.replace(np.nan, 0)\n",
    "\n",
    "    dff.expenses = dff.expenses.replace(np.nan, 0)\n",
    "\n",
    "    dff.legal_costs = dff.legal_costs.replace(np.nan, 0)\n",
    "\n",
    "    dff.maintenance_preservation_cost = dff.maintenance_preservation_cost.replace(np.nan, 0)\n",
    "    dff.taxes_insurance = dff.taxes_insurance.replace(np.nan, 0)\n",
    "    dff.misc_expenses = dff.misc_expenses.replace(np.nan, 0)\n",
    "    dff.actual_loss_calc = dff.actual_loss_calc.replace(np.nan, 0)\n",
    "    dff.modification_cost = dff.modification_cost.replace(np.nan, 0)\n",
    "\n",
    "# remove null\n",
    "remove_nan(df1)\n",
    "remove_nan(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Processing the data, Change the numerical features to Dummy variables, Create the target variable,  Create Training and Testing datasets\n",
    "def process_data():\n",
    "    # Create target variable function\n",
    "    def f(row):\n",
    "        if row['current_loan_delinquency_status'] > 0:\n",
    "            val = 1\n",
    "        else:\n",
    "            val = 0\n",
    "        return val\n",
    "    # Create dummy variables\n",
    "    df1_dummies = pd.get_dummies(df1[['repurchase_flag', 'modification_flag']])\n",
    "    df2_dummies = pd.get_dummies(df2[['repurchase_flag', 'modification_flag']])\n",
    "\n",
    "    df1_d = df1.drop(['loan_sequence_no', 'repurchase_flag', 'modification_flag'], axis=1)\n",
    "    df2_d = df2.drop(['loan_sequence_no', 'repurchase_flag', 'modification_flag'], axis=1)\n",
    "\n",
    "    global df1_final\n",
    "    global df2_final\n",
    "    df1_final = pd.concat([df1_d, df1_dummies], axis=1)\n",
    "    df2_final = pd.concat([df2_d, df2_dummies], axis=1)\n",
    "\n",
    "    # create target variable\n",
    "    df1_final['Deliquent'] = df1_final.apply(f, axis=1)\n",
    "    df2_final['Deliquent'] = df2_final.apply(f, axis=1)\n",
    "\n",
    "    # Create training and testing set\n",
    "    train_all = df1_final.drop(['current_loan_delinquency_status'], axis=1)\n",
    "    test_all = df2_final.drop(['current_loan_delinquency_status'], axis=1)\n",
    "    \n",
    "#     X_train = df1_final.drop(['current_loan_delinquency_status', 'Deliquent'], axis=1)\n",
    "#     y_train = df1_final['Deliquent']\n",
    "\n",
    "#     X_test = df2_final.drop(['current_loan_delinquency_status', 'Deliquent'], axis=1)\n",
    "#     y_test = df2_final['Deliquent']\n",
    "\n",
    "#     X_train = preprocessing.minmax_scale(np.array(X_train).astype(float))  # scale between 0 and 1\n",
    "#     X_test = preprocessing.minmax_scale(np.array(X_test).astype(float))\n",
    "\n",
    "    return train_all, test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all, test_all = process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all.to_csv('train_all.csv', index=False)\n",
    "test_all.to_csv('test_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(X_train.columns))\n",
    "y = ['Deliquent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:9957..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_121\"; OpenJDK Runtime Environment (Zulu 8.20.0.5-macosx) (build 1.8.0_121-b15); OpenJDK 64-Bit Server VM (Zulu 8.20.0.5-macosx) (build 25.121-b15, mixed mode)\n",
      "  Starting server from /anaconda3/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/hf/c05h_6kd5wlds2ysv1yvpy1c0000gn/T/tmpdo3zi7w5\n",
      "  JVM stdout: /var/folders/hf/c05h_6kd5wlds2ysv1yvpy1c0000gn/T/tmpdo3zi7w5/h2o_wangying_started_from_python.out\n",
      "  JVM stderr: /var/folders/hf/c05h_6kd5wlds2ysv1yvpy1c0000gn/T/tmpdo3zi7w5/h2o_wangying_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:9957\n",
      "Connecting to H2O server at http://127.0.0.1:9957... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>15 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_wangying_kbgw7l</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.556 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:9957</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         01 secs\n",
       "H2O cluster timezone:       America/New_York\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.0.2\n",
       "H2O cluster version age:    15 days\n",
       "H2O cluster name:           H2O_from_python_wangying_kbgw7l\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.556 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:9957\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.6 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "\n",
    "h2o.init(strict_version_check=False,port=9957)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train_df = h2o.import_file('train_all.csv')\n",
    "test_df = h2o.import_file('test_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Deliquent'] = train_df['Deliquent'].asfactor()\n",
    "test_df['Deliquent'] = test_df['Deliquent'].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:200000\n",
      "Cols:25\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>monthly_reporting_period  </th><th>current_actual_upb  </th><th>loan_age          </th><th>remaning_months_on_legal_maturity  </th><th>zero_bal_code     </th><th>zero_bal_eff_date  </th><th>current_interest_rate  </th><th>current_deferred_upb  </th><th>ddlpi             </th><th>mi_recoveries    </th><th>net_sales_proceeds  </th><th>non_mi_recoveries  </th><th>expenses         </th><th>legal_costs       </th><th>maintenance_preservation_cost  </th><th>taxes_insurance  </th><th>misc_expenses    </th><th>actual_loss_calc  </th><th>modification_cost  </th><th>repurchase_flag_0  </th><th>repurchase_flag_N  </th><th>repurchase_flag_Y   </th><th>modification_flag_0  </th><th>modification_flag_Y  </th><th>Deliquent  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int                       </td><td>real                </td><td>int               </td><td>int                                </td><td>int               </td><td>int                </td><td>real                   </td><td>real                  </td><td>int               </td><td>int              </td><td>int                 </td><td>int                </td><td>int              </td><td>int               </td><td>int                            </td><td>int              </td><td>int              </td><td>int               </td><td>real               </td><td>int                </td><td>int                </td><td>int                 </td><td>int                  </td><td>int                  </td><td>enum       </td></tr>\n",
       "<tr><td>mins   </td><td>200602.0                  </td><td>0.0                 </td><td>0.0               </td><td>0.0                                </td><td>0.0               </td><td>0.0                </td><td>0.0                    </td><td>0.0                   </td><td>0.0               </td><td>0.0              </td><td>0.0                 </td><td>-4479.0            </td><td>-106498.0        </td><td>-14016.0          </td><td>-84253.0                       </td><td>-78088.0         </td><td>-9866.0          </td><td>-310378.0         </td><td>0.0                </td><td>0.0                </td><td>0.0                </td><td>0.0                 </td><td>0.0                  </td><td>0.0                  </td><td>           </td></tr>\n",
       "<tr><td>mean   </td><td>200944.17248499996        </td><td>148010.13423979998  </td><td>44.76667500000002 </td><td>320.3400449999999                  </td><td>0.0212            </td><td>2805.312715        </td><td>6.255471470000001      </td><td>447.3755742           </td><td>307.660345        </td><td>12.396625        </td><td>112.57902           </td><td>7.914415           </td><td>-18.064845       </td><td>-3.69354          </td><td>-5.64695                       </td><td>-7.853915        </td><td>-0.87043         </td><td>-84.159775        </td><td>14.670465549999998 </td><td>0.98604            </td><td>0.01387            </td><td>9e-05               </td><td>0.999225             </td><td>0.000775             </td><td>           </td></tr>\n",
       "<tr><td>maxs   </td><td>201803.0                  </td><td>793000.0            </td><td>145.0             </td><td>480.0                              </td><td>15.0              </td><td>201803.0           </td><td>8.25                   </td><td>172060.01             </td><td>201801.0          </td><td>110827.0         </td><td>519200.0            </td><td>292124.0           </td><td>246.0            </td><td>0.0               </td><td>0.0                            </td><td>2341.0           </td><td>426.0            </td><td>3362.0            </td><td>131400.3           </td><td>1.0                </td><td>1.0                </td><td>1.0                 </td><td>1.0                  </td><td>1.0                  </td><td>           </td></tr>\n",
       "<tr><td>sigma  </td><td>296.624968581185          </td><td>85840.7270786279    </td><td>35.569494519729645</td><td>40.91893713422987                  </td><td>0.2960591127714046</td><td>23581.21673081728  </td><td>0.6023352295978404     </td><td>6176.556321254537     </td><td>7859.4999260999375</td><td>847.8208627974935</td><td>4213.490433332441   </td><td>1022.6834164769953 </td><td>767.4886757760426</td><td>133.98973262347621</td><td>336.7844779894414              </td><td>423.7957492216717</td><td>41.83082177896286</td><td>3167.869488546274 </td><td>856.1131869474124  </td><td>0.11732513467256762</td><td>0.11695166304271797</td><td>0.009486429779519258</td><td>0.02782810175014162  </td><td>0.02782810175014162  </td><td>           </td></tr>\n",
       "<tr><td>zeros  </td><td>0                         </td><td>2791                </td><td>3241              </td><td>138                                </td><td>197209            </td><td>197209             </td><td>138                    </td><td>198356                </td><td>199694            </td><td>199942           </td><td>199774              </td><td>199822             </td><td>199773           </td><td>199796            </td><td>199795                         </td><td>199809           </td><td>199776           </td><td>199788            </td><td>199891             </td><td>2792               </td><td>197226             </td><td>199982              </td><td>155                  </td><td>199845               </td><td>           </td></tr>\n",
       "<tr><td>missing</td><td>0                         </td><td>0                   </td><td>0                 </td><td>0                                  </td><td>0                 </td><td>0                  </td><td>0                      </td><td>0                     </td><td>0                 </td><td>0                </td><td>0                   </td><td>0                  </td><td>0                </td><td>0                 </td><td>0                              </td><td>0                </td><td>0                </td><td>0                 </td><td>0                  </td><td>0                  </td><td>0                  </td><td>0                   </td><td>0                    </td><td>0                    </td><td>0          </td></tr>\n",
       "<tr><td>0      </td><td>200603.0                  </td><td>130000.0            </td><td>0.0               </td><td>360.0                              </td><td>0.0               </td><td>0.0                </td><td>6.5                    </td><td>0.0                   </td><td>0.0               </td><td>0.0              </td><td>0.0                 </td><td>0.0                </td><td>0.0              </td><td>0.0               </td><td>0.0                            </td><td>0.0              </td><td>0.0              </td><td>0.0               </td><td>0.0                </td><td>1.0                </td><td>0.0                </td><td>0.0                 </td><td>1.0                  </td><td>0.0                  </td><td>0          </td></tr>\n",
       "<tr><td>1      </td><td>200604.0                  </td><td>130000.0            </td><td>1.0               </td><td>359.0                              </td><td>0.0               </td><td>0.0                </td><td>6.5                    </td><td>0.0                   </td><td>0.0               </td><td>0.0              </td><td>0.0                 </td><td>0.0                </td><td>0.0              </td><td>0.0               </td><td>0.0                            </td><td>0.0              </td><td>0.0              </td><td>0.0               </td><td>0.0                </td><td>1.0                </td><td>0.0                </td><td>0.0                 </td><td>1.0                  </td><td>0.0                  </td><td>0          </td></tr>\n",
       "<tr><td>2      </td><td>200605.0                  </td><td>130000.0            </td><td>2.0               </td><td>358.0                              </td><td>0.0               </td><td>0.0                </td><td>6.5                    </td><td>0.0                   </td><td>0.0               </td><td>0.0              </td><td>0.0                 </td><td>0.0                </td><td>0.0              </td><td>0.0               </td><td>0.0                            </td><td>0.0              </td><td>0.0              </td><td>0.0               </td><td>0.0                </td><td>1.0                </td><td>0.0                </td><td>0.0                 </td><td>1.0                  </td><td>0.0                  </td><td>0          </td></tr>\n",
       "<tr><td>3      </td><td>200606.0                  </td><td>130000.0            </td><td>3.0               </td><td>357.0                              </td><td>0.0               </td><td>0.0                </td><td>6.5                    </td><td>0.0                   </td><td>0.0               </td><td>0.0              </td><td>0.0                 </td><td>0.0                </td><td>0.0              </td><td>0.0               </td><td>0.0                            </td><td>0.0              </td><td>0.0              </td><td>0.0               </td><td>0.0                </td><td>1.0                </td><td>0.0                </td><td>0.0                 </td><td>1.0                  </td><td>0.0                  </td><td>0          </td></tr>\n",
       "<tr><td>4      </td><td>200607.0                  </td><td>129000.0            </td><td>4.0               </td><td>356.0                              </td><td>0.0               </td><td>0.0                </td><td>6.5                    </td><td>0.0                   </td><td>0.0               </td><td>0.0              </td><td>0.0                 </td><td>0.0                </td><td>0.0              </td><td>0.0               </td><td>0.0                            </td><td>0.0              </td><td>0.0              </td><td>0.0               </td><td>0.0                </td><td>1.0                </td><td>0.0                </td><td>0.0                 </td><td>1.0                  </td><td>0.0                  </td><td>0          </td></tr>\n",
       "<tr><td>5      </td><td>200608.0                  </td><td>129000.0            </td><td>5.0               </td><td>355.0                              </td><td>0.0               </td><td>0.0                </td><td>6.5                    </td><td>0.0                   </td><td>0.0               </td><td>0.0              </td><td>0.0                 </td><td>0.0                </td><td>0.0              </td><td>0.0               </td><td>0.0                            </td><td>0.0              </td><td>0.0              </td><td>0.0               </td><td>0.0                </td><td>1.0                </td><td>0.0                </td><td>0.0                 </td><td>1.0                  </td><td>0.0                  </td><td>0          </td></tr>\n",
       "<tr><td>6      </td><td>200609.0                  </td><td>129000.0            </td><td>6.0               </td><td>354.0                              </td><td>0.0               </td><td>0.0                </td><td>6.5                    </td><td>0.0                   </td><td>0.0               </td><td>0.0              </td><td>0.0                 </td><td>0.0                </td><td>0.0              </td><td>0.0               </td><td>0.0                            </td><td>0.0              </td><td>0.0              </td><td>0.0               </td><td>0.0                </td><td>1.0                </td><td>0.0                </td><td>0.0                 </td><td>1.0                  </td><td>0.0                  </td><td>0          </td></tr>\n",
       "<tr><td>7      </td><td>200610.0                  </td><td>129121.64           </td><td>7.0               </td><td>353.0                              </td><td>0.0               </td><td>0.0                </td><td>6.5                    </td><td>0.0                   </td><td>0.0               </td><td>0.0              </td><td>0.0                 </td><td>0.0                </td><td>0.0              </td><td>0.0               </td><td>0.0                            </td><td>0.0              </td><td>0.0              </td><td>0.0               </td><td>0.0                </td><td>1.0                </td><td>0.0                </td><td>0.0                 </td><td>1.0                  </td><td>0.0                  </td><td>0          </td></tr>\n",
       "<tr><td>8      </td><td>200611.0                  </td><td>128999.36           </td><td>8.0               </td><td>352.0                              </td><td>0.0               </td><td>0.0                </td><td>6.5                    </td><td>0.0                   </td><td>0.0               </td><td>0.0              </td><td>0.0                 </td><td>0.0                </td><td>0.0              </td><td>0.0               </td><td>0.0                            </td><td>0.0              </td><td>0.0              </td><td>0.0               </td><td>0.0                </td><td>1.0                </td><td>0.0                </td><td>0.0                 </td><td>1.0                  </td><td>0.0                  </td><td>0          </td></tr>\n",
       "<tr><td>9      </td><td>200612.0                  </td><td>128876.42           </td><td>9.0               </td><td>351.0                              </td><td>0.0               </td><td>0.0                </td><td>6.5                    </td><td>0.0                   </td><td>0.0               </td><td>0.0              </td><td>0.0                 </td><td>0.0                </td><td>0.0              </td><td>0.0               </td><td>0.0                            </td><td>0.0              </td><td>0.0              </td><td>0.0               </td><td>0.0                </td><td>1.0                </td><td>0.0                </td><td>0.0                 </td><td>1.0                  </td><td>0.0                  </td><td>0          </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deliquent'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_df.col_names[:24]\n",
    "Y = train_df.col_names[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.automl import H2OAutoML\n",
    "# Set up AutoML\n",
    "aml = H2OAutoML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "aml.train(x=X,y=Y,training_frame=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>auc</th>\n",
       "      <th>logloss</th>\n",
       "      <th>mean_per_class_error</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StackedEnsemble_AllModels_AutoML_20181207_133501</td>\n",
       "      <td>0.911731</td>\n",
       "      <td>0.139201</td>\n",
       "      <td>0.210976</td>\n",
       "      <td>0.187376</td>\n",
       "      <td>0.035110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StackedEnsemble_BestOfFamily_AutoML_20181207_1...</td>\n",
       "      <td>0.911731</td>\n",
       "      <td>0.139201</td>\n",
       "      <td>0.210976</td>\n",
       "      <td>0.187376</td>\n",
       "      <td>0.035110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DRF_1_AutoML_20181207_133501</td>\n",
       "      <td>0.907181</td>\n",
       "      <td>0.155591</td>\n",
       "      <td>0.219043</td>\n",
       "      <td>0.203407</td>\n",
       "      <td>0.041374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XRT_1_AutoML_20181207_133501</td>\n",
       "      <td>0.906353</td>\n",
       "      <td>0.157899</td>\n",
       "      <td>0.215183</td>\n",
       "      <td>0.205562</td>\n",
       "      <td>0.042256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GLM_grid_1_AutoML_20181207_133501_model_1</td>\n",
       "      <td>0.745118</td>\n",
       "      <td>0.221634</td>\n",
       "      <td>0.329522</td>\n",
       "      <td>0.241570</td>\n",
       "      <td>0.058356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            model_id       auc   logloss  \\\n",
       "0   StackedEnsemble_AllModels_AutoML_20181207_133501  0.911731  0.139201   \n",
       "1  StackedEnsemble_BestOfFamily_AutoML_20181207_1...  0.911731  0.139201   \n",
       "2                       DRF_1_AutoML_20181207_133501  0.907181  0.155591   \n",
       "3                       XRT_1_AutoML_20181207_133501  0.906353  0.157899   \n",
       "4          GLM_grid_1_AutoML_20181207_133501_model_1  0.745118  0.221634   \n",
       "\n",
       "   mean_per_class_error      rmse       mse  \n",
       "0              0.210976  0.187376  0.035110  \n",
       "1              0.210976  0.187376  0.035110  \n",
       "2              0.219043  0.203407  0.041374  \n",
       "3              0.215183  0.205562  0.042256  \n",
       "4              0.329522  0.241570  0.058356  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml_leaderboard_df=aml.leaderboard.as_data_frame()\n",
    "aml_leaderboard_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set=aml_leaderboard_df['model_id']\n",
    "mod_best=h2o.get_model(model_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
      "Model Key:  StackedEnsemble_AllModels_AutoML_20181207_133501\n",
      "No model summary for this model\n",
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0275125222633876\n",
      "RMSE: 0.1658689912653586\n",
      "LogLoss: 0.10626235967457597\n",
      "Null degrees of freedom: 180106\n",
      "Residual degrees of freedom: 180104\n",
      "Null deviance: 88062.81280740295\n",
      "Residual deviance: 38277.18962781771\n",
      "AIC: 38283.18962781771\n",
      "AUC: 0.958091637980924\n",
      "pr_auc: 0.6846908221204717\n",
      "Gini: 0.916183275961848\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.18780698817450475: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>165893.0</td>\n",
       "<td>2238.0</td>\n",
       "<td>0.0133</td>\n",
       "<td> (2238.0/168131.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>3483.0</td>\n",
       "<td>8493.0</td>\n",
       "<td>0.2908</td>\n",
       "<td> (3483.0/11976.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>169376.0</td>\n",
       "<td>10731.0</td>\n",
       "<td>0.0318</td>\n",
       "<td> (5721.0/180107.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0       1      Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "0      165893  2238   0.0133   (2238.0/168131.0)\n",
       "1      3483    8493   0.2908   (3483.0/11976.0)\n",
       "Total  169376  10731  0.0318   (5721.0/180107.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1878070</td>\n",
       "<td>0.7480513</td>\n",
       "<td>220.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1080104</td>\n",
       "<td>0.7628374</td>\n",
       "<td>264.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3313988</td>\n",
       "<td>0.8015241</td>\n",
       "<td>172.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.2191566</td>\n",
       "<td>0.9687686</td>\n",
       "<td>207.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9998833</td>\n",
       "<td>0.9993280</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0110240</td>\n",
       "<td>1.0</td>\n",
       "<td>395.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9998833</td>\n",
       "<td>0.9999941</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1950607</td>\n",
       "<td>0.7324859</td>\n",
       "<td>217.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0630838</td>\n",
       "<td>0.8946226</td>\n",
       "<td>305.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0703042</td>\n",
       "<td>0.8980241</td>\n",
       "<td>297.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.187807     0.748051  220\n",
       "max f2                       0.10801      0.762837  264\n",
       "max f0point5                 0.331399     0.801524  172\n",
       "max accuracy                 0.219157     0.968769  207\n",
       "max precision                0.999883     0.999328  0\n",
       "max recall                   0.011024     1         395\n",
       "max specificity              0.999883     0.999994  0\n",
       "max absolute_mcc             0.195061     0.732486  217\n",
       "max min_per_class_accuracy   0.0630838    0.894623  305\n",
       "max mean_per_class_accuracy  0.0703042    0.898024  297"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  6.65 %, avg score:  6.66 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100163</td>\n",
       "<td>0.9986120</td>\n",
       "<td>15.0139852</td>\n",
       "<td>15.0139852</td>\n",
       "<td>0.9983370</td>\n",
       "<td>0.9997403</td>\n",
       "<td>0.9983370</td>\n",
       "<td>0.9997403</td>\n",
       "<td>0.1503841</td>\n",
       "<td>0.1503841</td>\n",
       "<td>1401.3985241</td>\n",
       "<td>1401.3985241</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200048</td>\n",
       "<td>0.9492644</td>\n",
       "<td>14.7046090</td>\n",
       "<td>14.8595118</td>\n",
       "<td>0.9777654</td>\n",
       "<td>0.9834698</td>\n",
       "<td>0.9880655</td>\n",
       "<td>0.9916163</td>\n",
       "<td>0.1468771</td>\n",
       "<td>0.2972612</td>\n",
       "<td>1370.4609005</td>\n",
       "<td>1385.9511789</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300099</td>\n",
       "<td>0.6921901</td>\n",
       "<td>13.0944410</td>\n",
       "<td>14.2710460</td>\n",
       "<td>0.8706992</td>\n",
       "<td>0.8408838</td>\n",
       "<td>0.9489362</td>\n",
       "<td>0.9413629</td>\n",
       "<td>0.1310120</td>\n",
       "<td>0.4282732</td>\n",
       "<td>1209.4440963</td>\n",
       "<td>1327.1045993</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400040</td>\n",
       "<td>0.4112947</td>\n",
       "<td>11.5549609</td>\n",
       "<td>13.5924959</td>\n",
       "<td>0.7683333</td>\n",
       "<td>0.5423758</td>\n",
       "<td>0.9038168</td>\n",
       "<td>0.8416853</td>\n",
       "<td>0.1154810</td>\n",
       "<td>0.5437542</td>\n",
       "<td>1055.4960894</td>\n",
       "<td>1259.2495933</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500036</td>\n",
       "<td>0.2566948</td>\n",
       "<td>9.4693059</td>\n",
       "<td>12.7679495</td>\n",
       "<td>0.6296502</td>\n",
       "<td>0.3254250</td>\n",
       "<td>0.8489896</td>\n",
       "<td>0.7384447</td>\n",
       "<td>0.0946894</td>\n",
       "<td>0.6384436</td>\n",
       "<td>846.9305908</td>\n",
       "<td>1176.7949494</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000017</td>\n",
       "<td>0.0967974</td>\n",
       "<td>3.9430390</td>\n",
       "<td>8.3557392</td>\n",
       "<td>0.2621877</td>\n",
       "<td>0.1458913</td>\n",
       "<td>0.5556049</td>\n",
       "<td>0.4421845</td>\n",
       "<td>0.1971443</td>\n",
       "<td>0.8355878</td>\n",
       "<td>294.3039021</td>\n",
       "<td>735.5739244</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1499997</td>\n",
       "<td>0.0651047</td>\n",
       "<td>1.1139377</td>\n",
       "<td>5.9418948</td>\n",
       "<td>0.0740700</td>\n",
       "<td>0.0786810</td>\n",
       "<td>0.3950992</td>\n",
       "<td>0.3210211</td>\n",
       "<td>0.0556947</td>\n",
       "<td>0.8912826</td>\n",
       "<td>11.3937750</td>\n",
       "<td>494.1894765</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000089</td>\n",
       "<td>0.0509309</td>\n",
       "<td>0.4975708</td>\n",
       "<td>4.5806249</td>\n",
       "<td>0.0330854</td>\n",
       "<td>0.0570980</td>\n",
       "<td>0.3045832</td>\n",
       "<td>0.2550312</td>\n",
       "<td>0.0248831</td>\n",
       "<td>0.9161657</td>\n",
       "<td>-50.2429176</td>\n",
       "<td>358.0624861</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999994</td>\n",
       "<td>0.0363126</td>\n",
       "<td>0.2563702</td>\n",
       "<td>3.1393400</td>\n",
       "<td>0.0170470</td>\n",
       "<td>0.0428245</td>\n",
       "<td>0.2087467</td>\n",
       "<td>0.1843022</td>\n",
       "<td>0.0256346</td>\n",
       "<td>0.9418003</td>\n",
       "<td>-74.3629776</td>\n",
       "<td>213.9340034</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000011</td>\n",
       "<td>0.0261805</td>\n",
       "<td>0.1786877</td>\n",
       "<td>2.3991667</td>\n",
       "<td>0.0118816</td>\n",
       "<td>0.0310841</td>\n",
       "<td>0.1595297</td>\n",
       "<td>0.1459971</td>\n",
       "<td>0.0178691</td>\n",
       "<td>0.9596693</td>\n",
       "<td>-82.1312262</td>\n",
       "<td>139.9166686</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000694</td>\n",
       "<td>0.0174037</td>\n",
       "<td>0.2202904</td>\n",
       "<td>1.9631544</td>\n",
       "<td>0.0146479</td>\n",
       "<td>0.0215317</td>\n",
       "<td>0.1305376</td>\n",
       "<td>0.1210905</td>\n",
       "<td>0.0220441</td>\n",
       "<td>0.9817134</td>\n",
       "<td>-77.9709561</td>\n",
       "<td>96.3154355</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999989</td>\n",
       "<td>0.0134812</td>\n",
       "<td>0.1128050</td>\n",
       "<td>1.6549797</td>\n",
       "<td>0.0075008</td>\n",
       "<td>0.0150812</td>\n",
       "<td>0.1100459</td>\n",
       "<td>0.1034347</td>\n",
       "<td>0.0112725</td>\n",
       "<td>0.9929860</td>\n",
       "<td>-88.7195006</td>\n",
       "<td>65.4979683</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000006</td>\n",
       "<td>0.0119796</td>\n",
       "<td>0.0492644</td>\n",
       "<td>1.4255881</td>\n",
       "<td>0.0032758</td>\n",
       "<td>0.0126212</td>\n",
       "<td>0.0947928</td>\n",
       "<td>0.0904611</td>\n",
       "<td>0.0049265</td>\n",
       "<td>0.9979125</td>\n",
       "<td>-95.0735624</td>\n",
       "<td>42.5588143</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999967</td>\n",
       "<td>0.0112472</td>\n",
       "<td>0.0192058</td>\n",
       "<td>1.2497965</td>\n",
       "<td>0.0012771</td>\n",
       "<td>0.0115698</td>\n",
       "<td>0.0831037</td>\n",
       "<td>0.0806001</td>\n",
       "<td>0.0019205</td>\n",
       "<td>0.9998330</td>\n",
       "<td>-98.0794177</td>\n",
       "<td>24.9796454</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999983</td>\n",
       "<td>0.0105789</td>\n",
       "<td>0.0016700</td>\n",
       "<td>1.1111132</td>\n",
       "<td>0.0001110</td>\n",
       "<td>0.0108994</td>\n",
       "<td>0.0738821</td>\n",
       "<td>0.0728554</td>\n",
       "<td>0.0001670</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.8330021</td>\n",
       "<td>11.1113168</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0088878</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0103503</td>\n",
       "<td>0.0664938</td>\n",
       "<td>0.0666048</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100163                   0.998612           15.014      15.014             0.998337         0.99974    0.998337                    0.99974             0.150384        0.150384                   1401.4    1401.4\n",
       "    2        0.0200048                   0.949264           14.7046     14.8595            0.977765         0.98347    0.988066                    0.991616            0.146877        0.297261                   1370.46   1385.95\n",
       "    3        0.0300099                   0.69219            13.0944     14.271             0.870699         0.840884   0.948936                    0.941363            0.131012        0.428273                   1209.44   1327.1\n",
       "    4        0.040004                    0.411295           11.555      13.5925            0.768333         0.542376   0.903817                    0.841685            0.115481        0.543754                   1055.5    1259.25\n",
       "    5        0.0500036                   0.256695           9.46931     12.7679            0.62965          0.325425   0.84899                     0.738445            0.0946894       0.638444                   846.931   1176.79\n",
       "    6        0.100002                    0.0967974          3.94304     8.35574            0.262188         0.145891   0.555605                    0.442184            0.197144        0.835588                   294.304   735.574\n",
       "    7        0.15                        0.0651047          1.11394     5.94189            0.07407          0.078681   0.395099                    0.321021            0.0556947       0.891283                   11.3938   494.189\n",
       "    8        0.200009                    0.0509309          0.497571    4.58062            0.0330854        0.057098   0.304583                    0.255031            0.0248831       0.916166                   -50.2429  358.062\n",
       "    9        0.299999                    0.0363126          0.25637     3.13934            0.017047         0.0428245  0.208747                    0.184302            0.0256346       0.9418                     -74.363   213.934\n",
       "    10       0.400001                    0.0261805          0.178688    2.39917            0.0118816        0.0310841  0.15953                     0.145997            0.0178691       0.959669                   -82.1312  139.917\n",
       "    11       0.500069                    0.0174037          0.22029     1.96315            0.0146479        0.0215317  0.130538                    0.12109             0.0220441       0.981713                   -77.971   96.3154\n",
       "    12       0.599999                    0.0134812          0.112805    1.65498            0.00750083       0.0150812  0.110046                    0.103435            0.0112725       0.992986                   -88.7195  65.498\n",
       "    13       0.700001                    0.0119796          0.0492644   1.42559            0.00327578       0.0126212  0.0947928                   0.0904611           0.00492652      0.997912                   -95.0736  42.5588\n",
       "    14       0.799997                    0.0112472          0.0192058   1.2498             0.00127707       0.0115698  0.0831037                   0.0806001           0.00192051      0.999833                   -98.0794  24.9796\n",
       "    15       0.899998                    0.0105789          0.00166998  1.11111            0.000111043      0.0108994  0.0738821                   0.0728554           0.000167001     1                          -99.833   11.1113\n",
       "    16       1                           0.00888776         0           1                  0                0.0103503  0.0664938                   0.0666048           0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.03561706521918558\n",
      "RMSE: 0.1887248399633328\n",
      "LogLoss: 0.14083029209817322\n",
      "Null degrees of freedom: 19892\n",
      "Residual degrees of freedom: 19890\n",
      "Null deviance: 9241.789508846665\n",
      "Residual deviance: 5603.07400141792\n",
      "AIC: 5609.07400141792\n",
      "AUC: 0.9062319542981951\n",
      "pr_auc: 0.5281877597850334\n",
      "Gini: 0.8124639085963903\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.19047175908725777: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>18271.0</td>\n",
       "<td>391.0</td>\n",
       "<td>0.021</td>\n",
       "<td> (391.0/18662.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>508.0</td>\n",
       "<td>723.0</td>\n",
       "<td>0.4127</td>\n",
       "<td> (508.0/1231.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>18779.0</td>\n",
       "<td>1114.0</td>\n",
       "<td>0.0452</td>\n",
       "<td> (899.0/19893.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0      1     Error    Rate\n",
       "-----  -----  ----  -------  ---------------\n",
       "0      18271  391   0.021    (391.0/18662.0)\n",
       "1      508    723   0.4127   (508.0/1231.0)\n",
       "Total  18779  1114  0.0452   (899.0/19893.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1904718</td>\n",
       "<td>0.6166311</td>\n",
       "<td>205.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1054705</td>\n",
       "<td>0.6310823</td>\n",
       "<td>254.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3494196</td>\n",
       "<td>0.6703595</td>\n",
       "<td>154.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3494196</td>\n",
       "<td>0.9576233</td>\n",
       "<td>154.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9984762</td>\n",
       "<td>0.9526627</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0105420</td>\n",
       "<td>1.0</td>\n",
       "<td>397.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9998251</td>\n",
       "<td>0.9996249</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1918069</td>\n",
       "<td>0.5935792</td>\n",
       "<td>204.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0499399</td>\n",
       "<td>0.8245329</td>\n",
       "<td>316.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0630052</td>\n",
       "<td>0.8362863</td>\n",
       "<td>297.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.190472     0.616631  205\n",
       "max f2                       0.105471     0.631082  254\n",
       "max f0point5                 0.34942      0.670359  154\n",
       "max accuracy                 0.34942      0.957623  154\n",
       "max precision                0.998476     0.952663  1\n",
       "max recall                   0.010542     1         397\n",
       "max specificity              0.999825     0.999625  0\n",
       "max absolute_mcc             0.191807     0.593579  204\n",
       "max min_per_class_accuracy   0.0499399    0.824533  316\n",
       "max mean_per_class_accuracy  0.0630052    0.836286  297"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  6.19 %, avg score:  6.40 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100035</td>\n",
       "<td>0.9941379</td>\n",
       "<td>15.1043520</td>\n",
       "<td>15.1043520</td>\n",
       "<td>0.9346734</td>\n",
       "<td>0.9989995</td>\n",
       "<td>0.9346734</td>\n",
       "<td>0.9989995</td>\n",
       "<td>0.1510967</td>\n",
       "<td>0.1510967</td>\n",
       "<td>1410.4351979</td>\n",
       "<td>1410.4351979</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200070</td>\n",
       "<td>0.8864101</td>\n",
       "<td>12.7493724</td>\n",
       "<td>13.9268622</td>\n",
       "<td>0.7889447</td>\n",
       "<td>0.9603095</td>\n",
       "<td>0.8618090</td>\n",
       "<td>0.9796545</td>\n",
       "<td>0.1275386</td>\n",
       "<td>0.2786353</td>\n",
       "<td>1174.9372370</td>\n",
       "<td>1292.6862174</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300106</td>\n",
       "<td>0.5814216</td>\n",
       "<td>10.5568051</td>\n",
       "<td>12.8035098</td>\n",
       "<td>0.6532663</td>\n",
       "<td>0.7508767</td>\n",
       "<td>0.7922948</td>\n",
       "<td>0.9033953</td>\n",
       "<td>0.1056052</td>\n",
       "<td>0.3842405</td>\n",
       "<td>955.6805147</td>\n",
       "<td>1180.3509832</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400141</td>\n",
       "<td>0.3489496</td>\n",
       "<td>9.5823308</td>\n",
       "<td>11.9982151</td>\n",
       "<td>0.5929648</td>\n",
       "<td>0.4455735</td>\n",
       "<td>0.7424623</td>\n",
       "<td>0.7889398</td>\n",
       "<td>0.0958570</td>\n",
       "<td>0.4800975</td>\n",
       "<td>858.2330826</td>\n",
       "<td>1099.8215080</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500176</td>\n",
       "<td>0.2190275</td>\n",
       "<td>7.0649388</td>\n",
       "<td>11.0115598</td>\n",
       "<td>0.4371859</td>\n",
       "<td>0.2748753</td>\n",
       "<td>0.6814070</td>\n",
       "<td>0.6861269</td>\n",
       "<td>0.0706742</td>\n",
       "<td>0.5507717</td>\n",
       "<td>606.4938829</td>\n",
       "<td>1001.1559830</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000352</td>\n",
       "<td>0.0985074</td>\n",
       "<td>3.1183178</td>\n",
       "<td>7.0649388</td>\n",
       "<td>0.1929648</td>\n",
       "<td>0.1399079</td>\n",
       "<td>0.4371859</td>\n",
       "<td>0.4130174</td>\n",
       "<td>0.1559708</td>\n",
       "<td>0.7067425</td>\n",
       "<td>211.8317828</td>\n",
       "<td>606.4938829</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500025</td>\n",
       "<td>0.0658349</td>\n",
       "<td>1.4306669</td>\n",
       "<td>5.1881069</td>\n",
       "<td>0.0885312</td>\n",
       "<td>0.0797837</td>\n",
       "<td>0.3210456</td>\n",
       "<td>0.3020140</td>\n",
       "<td>0.0714866</td>\n",
       "<td>0.7782291</td>\n",
       "<td>43.0666861</td>\n",
       "<td>418.8106947</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000201</td>\n",
       "<td>0.0518087</td>\n",
       "<td>0.7958207</td>\n",
       "<td>4.0897594</td>\n",
       "<td>0.0492462</td>\n",
       "<td>0.0579384</td>\n",
       "<td>0.2530787</td>\n",
       "<td>0.2409798</td>\n",
       "<td>0.0398050</td>\n",
       "<td>0.8180341</td>\n",
       "<td>-20.4179304</td>\n",
       "<td>308.9759417</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000050</td>\n",
       "<td>0.0368738</td>\n",
       "<td>0.4306092</td>\n",
       "<td>2.8702471</td>\n",
       "<td>0.0266466</td>\n",
       "<td>0.0437700</td>\n",
       "<td>0.1776139</td>\n",
       "<td>0.1752542</td>\n",
       "<td>0.0430544</td>\n",
       "<td>0.8610885</td>\n",
       "<td>-56.9390788</td>\n",
       "<td>187.0247058</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000402</td>\n",
       "<td>0.0268144</td>\n",
       "<td>0.3816691</td>\n",
       "<td>2.2479462</td>\n",
       "<td>0.0236181</td>\n",
       "<td>0.0318142</td>\n",
       "<td>0.1391053</td>\n",
       "<td>0.1393852</td>\n",
       "<td>0.0381803</td>\n",
       "<td>0.8992689</td>\n",
       "<td>-61.8330891</td>\n",
       "<td>124.7946214</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000251</td>\n",
       "<td>0.0177499</td>\n",
       "<td>0.4224845</td>\n",
       "<td>1.8829273</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.0221308</td>\n",
       "<td>0.1165175</td>\n",
       "<td>0.1159390</td>\n",
       "<td>0.0422421</td>\n",
       "<td>0.9415110</td>\n",
       "<td>-57.7515490</td>\n",
       "<td>88.2927281</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000101</td>\n",
       "<td>0.0135764</td>\n",
       "<td>0.2681152</td>\n",
       "<td>1.6138370</td>\n",
       "<td>0.0165913</td>\n",
       "<td>0.0152943</td>\n",
       "<td>0.0998660</td>\n",
       "<td>0.0991677</td>\n",
       "<td>0.0268075</td>\n",
       "<td>0.9683184</td>\n",
       "<td>-73.1884830</td>\n",
       "<td>61.3837025</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999950</td>\n",
       "<td>0.0119953</td>\n",
       "<td>0.1462446</td>\n",
       "<td>1.4042111</td>\n",
       "<td>0.0090498</td>\n",
       "<td>0.0126799</td>\n",
       "<td>0.0868941</td>\n",
       "<td>0.0868141</td>\n",
       "<td>0.0146223</td>\n",
       "<td>0.9829407</td>\n",
       "<td>-85.3755362</td>\n",
       "<td>40.4211082</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999799</td>\n",
       "<td>0.0112340</td>\n",
       "<td>0.0893717</td>\n",
       "<td>1.2398768</td>\n",
       "<td>0.0055304</td>\n",
       "<td>0.0115600</td>\n",
       "<td>0.0767249</td>\n",
       "<td>0.0774085</td>\n",
       "<td>0.0089358</td>\n",
       "<td>0.9918765</td>\n",
       "<td>-91.0628277</td>\n",
       "<td>23.9876818</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999648</td>\n",
       "<td>0.0105585</td>\n",
       "<td>0.0731223</td>\n",
       "<td>1.1102519</td>\n",
       "<td>0.0045249</td>\n",
       "<td>0.0108840</td>\n",
       "<td>0.0687036</td>\n",
       "<td>0.0700177</td>\n",
       "<td>0.0073111</td>\n",
       "<td>0.9991877</td>\n",
       "<td>-92.6877681</td>\n",
       "<td>11.0251911</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0097144</td>\n",
       "<td>0.0081206</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0005025</td>\n",
       "<td>0.0103435</td>\n",
       "<td>0.0618811</td>\n",
       "<td>0.0640482</td>\n",
       "<td>0.0008123</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.1879381</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100035                   0.994138           15.1044     15.1044            0.934673         0.999      0.934673                    0.999               0.151097        0.151097                   1410.44   1410.44\n",
       "    2        0.020007                    0.88641            12.7494     13.9269            0.788945         0.96031    0.861809                    0.979655            0.127539        0.278635                   1174.94   1292.69\n",
       "    3        0.0300106                   0.581422           10.5568     12.8035            0.653266         0.750877   0.792295                    0.903395            0.105605        0.38424                    955.681   1180.35\n",
       "    4        0.0400141                   0.34895            9.58233     11.9982            0.592965         0.445574   0.742462                    0.78894             0.095857        0.480097                   858.233   1099.82\n",
       "    5        0.0500176                   0.219027           7.06494     11.0116            0.437186         0.274875   0.681407                    0.686127            0.0706742       0.550772                   606.494   1001.16\n",
       "    6        0.100035                    0.0985074          3.11832     7.06494            0.192965         0.139908   0.437186                    0.413017            0.155971        0.706742                   211.832   606.494\n",
       "    7        0.150003                    0.0658349          1.43067     5.18811            0.0885312        0.0797837  0.321046                    0.302014            0.0714866       0.778229                   43.0667   418.811\n",
       "    8        0.20002                     0.0518087          0.795821    4.08976            0.0492462        0.0579384  0.253079                    0.24098             0.039805        0.818034                   -20.4179  308.976\n",
       "    9        0.300005                    0.0368738          0.430609    2.87025            0.0266466        0.04377    0.177614                    0.175254            0.0430544       0.861089                   -56.9391  187.025\n",
       "    10       0.40004                     0.0268144          0.381669    2.24795            0.0236181        0.0318142  0.139105                    0.139385            0.0381803       0.899269                   -61.8331  124.795\n",
       "    11       0.500025                    0.0177499          0.422485    1.88293            0.0261438        0.0221308  0.116518                    0.115939            0.0422421       0.941511                   -57.7515  88.2927\n",
       "    12       0.60001                     0.0135764          0.268115    1.61384            0.0165913        0.0152943  0.099866                    0.0991677           0.0268075       0.968318                   -73.1885  61.3837\n",
       "    13       0.699995                    0.0119953          0.146245    1.40421            0.00904977       0.0126799  0.0868941                   0.0868141           0.0146223       0.982941                   -85.3755  40.4211\n",
       "    14       0.79998                     0.011234           0.0893717   1.23988            0.00553042       0.01156    0.0767249                   0.0774085           0.00893582      0.991877                   -91.0628  23.9877\n",
       "    15       0.899965                    0.0105585          0.0731223   1.11025            0.00452489       0.010884   0.0687036                   0.0700177           0.00731113      0.999188                   -92.6878  11.0252\n",
       "    16       1                           0.0097144          0.00812062  1                  0.000502513      0.0103435  0.0618811                   0.0640482           0.000812348     1                          -99.1879  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.03510958573831718\n",
      "RMSE: 0.1873755206485553\n",
      "LogLoss: 0.13920070165984655\n",
      "Null degrees of freedom: 180106\n",
      "Residual degrees of freedom: 180104\n",
      "Null deviance: 88064.14142186\n",
      "Residual deviance: 50142.04154769996\n",
      "AIC: 50148.04154769996\n",
      "AUC: 0.9117309514497408\n",
      "pr_auc: 0.5655867878447075\n",
      "Gini: 0.8234619028994816\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2043320751396149: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>164898.0</td>\n",
       "<td>3233.0</td>\n",
       "<td>0.0192</td>\n",
       "<td> (3233.0/168131.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>4823.0</td>\n",
       "<td>7153.0</td>\n",
       "<td>0.4027</td>\n",
       "<td> (4823.0/11976.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>169721.0</td>\n",
       "<td>10386.0</td>\n",
       "<td>0.0447</td>\n",
       "<td> (8056.0/180107.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0       1      Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "0      164898  3233   0.0192   (3233.0/168131.0)\n",
       "1      4823    7153   0.4027   (4823.0/11976.0)\n",
       "Total  169721  10386  0.0447   (8056.0/180107.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2043321</td>\n",
       "<td>0.6397460</td>\n",
       "<td>212.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1088415</td>\n",
       "<td>0.6577074</td>\n",
       "<td>263.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4299877</td>\n",
       "<td>0.7093129</td>\n",
       "<td>142.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3385973</td>\n",
       "<td>0.9578084</td>\n",
       "<td>167.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9998772</td>\n",
       "<td>0.9627093</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0097825</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9998772</td>\n",
       "<td>0.9997086</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2249116</td>\n",
       "<td>0.6187788</td>\n",
       "<td>204.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0499322</td>\n",
       "<td>0.8329993</td>\n",
       "<td>320.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0649581</td>\n",
       "<td>0.8425367</td>\n",
       "<td>301.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.204332     0.639746  212\n",
       "max f2                       0.108842     0.657707  263\n",
       "max f0point5                 0.429988     0.709313  142\n",
       "max accuracy                 0.338597     0.957808  167\n",
       "max precision                0.999877     0.962709  0\n",
       "max recall                   0.0097825    1         399\n",
       "max specificity              0.999877     0.999709  0\n",
       "max absolute_mcc             0.224912     0.618779  204\n",
       "max min_per_class_accuracy   0.0499322    0.832999  320\n",
       "max mean_per_class_accuracy  0.0649581    0.842537  301"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  6.65 %, avg score:  6.65 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100052</td>\n",
       "<td>0.9979190</td>\n",
       "<td>14.3713367</td>\n",
       "<td>14.3713367</td>\n",
       "<td>0.9556049</td>\n",
       "<td>0.9996119</td>\n",
       "<td>0.9556049</td>\n",
       "<td>0.9996119</td>\n",
       "<td>0.1437876</td>\n",
       "<td>0.1437876</td>\n",
       "<td>1337.1336736</td>\n",
       "<td>1337.1336736</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200048</td>\n",
       "<td>0.9366244</td>\n",
       "<td>13.1351130</td>\n",
       "<td>13.7533964</td>\n",
       "<td>0.8734037</td>\n",
       "<td>0.9786123</td>\n",
       "<td>0.9145157</td>\n",
       "<td>0.9891151</td>\n",
       "<td>0.1313460</td>\n",
       "<td>0.2751336</td>\n",
       "<td>1213.5113045</td>\n",
       "<td>1275.3396445</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300044</td>\n",
       "<td>0.6721783</td>\n",
       "<td>11.5318443</td>\n",
       "<td>13.0130161</td>\n",
       "<td>0.7667962</td>\n",
       "<td>0.8181641</td>\n",
       "<td>0.8652850</td>\n",
       "<td>0.9321419</td>\n",
       "<td>0.1153140</td>\n",
       "<td>0.3904476</td>\n",
       "<td>1053.1844320</td>\n",
       "<td>1201.3016101</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400040</td>\n",
       "<td>0.3962600</td>\n",
       "<td>9.2020945</td>\n",
       "<td>12.0604179</td>\n",
       "<td>0.6118823</td>\n",
       "<td>0.5195895</td>\n",
       "<td>0.8019431</td>\n",
       "<td>0.8290181</td>\n",
       "<td>0.0920174</td>\n",
       "<td>0.4824649</td>\n",
       "<td>820.2094454</td>\n",
       "<td>1106.0417921</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500036</td>\n",
       "<td>0.2588735</td>\n",
       "<td>7.2230596</td>\n",
       "<td>11.0930537</td>\n",
       "<td>0.4802887</td>\n",
       "<td>0.3171203</td>\n",
       "<td>0.7376194</td>\n",
       "<td>0.7266500</td>\n",
       "<td>0.0722278</td>\n",
       "<td>0.5546927</td>\n",
       "<td>622.3059621</td>\n",
       "<td>1009.3053686</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000017</td>\n",
       "<td>0.0997466</td>\n",
       "<td>3.3585140</td>\n",
       "<td>7.2259985</td>\n",
       "<td>0.2233204</td>\n",
       "<td>0.1511155</td>\n",
       "<td>0.4804841</td>\n",
       "<td>0.4388987</td>\n",
       "<td>0.1679192</td>\n",
       "<td>0.7226119</td>\n",
       "<td>235.8513965</td>\n",
       "<td>622.5998543</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1499997</td>\n",
       "<td>0.0671994</td>\n",
       "<td>1.3444076</td>\n",
       "<td>5.2655408</td>\n",
       "<td>0.0893948</td>\n",
       "<td>0.0810978</td>\n",
       "<td>0.3501259</td>\n",
       "<td>0.3196362</td>\n",
       "<td>0.0672178</td>\n",
       "<td>0.7898297</td>\n",
       "<td>34.4407629</td>\n",
       "<td>426.5540807</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000033</td>\n",
       "<td>0.0518557</td>\n",
       "<td>0.7397596</td>\n",
       "<td>4.1340327</td>\n",
       "<td>0.0491894</td>\n",
       "<td>0.0587943</td>\n",
       "<td>0.2748876</td>\n",
       "<td>0.2544221</td>\n",
       "<td>0.0369906</td>\n",
       "<td>0.8268203</td>\n",
       "<td>-26.0240436</td>\n",
       "<td>313.4032677</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999994</td>\n",
       "<td>0.0358625</td>\n",
       "<td>0.4584347</td>\n",
       "<td>2.9088787</td>\n",
       "<td>0.0304831</td>\n",
       "<td>0.0430093</td>\n",
       "<td>0.1934224</td>\n",
       "<td>0.1839538</td>\n",
       "<td>0.0458417</td>\n",
       "<td>0.8726620</td>\n",
       "<td>-54.1565349</td>\n",
       "<td>190.8878686</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000011</td>\n",
       "<td>0.0253472</td>\n",
       "<td>0.3498606</td>\n",
       "<td>2.2691153</td>\n",
       "<td>0.0232636</td>\n",
       "<td>0.0304552</td>\n",
       "<td>0.1508821</td>\n",
       "<td>0.1455786</td>\n",
       "<td>0.0349866</td>\n",
       "<td>0.9076486</td>\n",
       "<td>-65.0139428</td>\n",
       "<td>126.9115277</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000028</td>\n",
       "<td>0.0179124</td>\n",
       "<td>0.3239759</td>\n",
       "<td>1.8800831</td>\n",
       "<td>0.0215424</td>\n",
       "<td>0.0213885</td>\n",
       "<td>0.1250139</td>\n",
       "<td>0.1207403</td>\n",
       "<td>0.0323981</td>\n",
       "<td>0.9400468</td>\n",
       "<td>-67.6024100</td>\n",
       "<td>88.0083082</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000044</td>\n",
       "<td>0.0138157</td>\n",
       "<td>0.2697016</td>\n",
       "<td>1.6116837</td>\n",
       "<td>0.0179335</td>\n",
       "<td>0.0155379</td>\n",
       "<td>0.1071670</td>\n",
       "<td>0.1032064</td>\n",
       "<td>0.0269706</td>\n",
       "<td>0.9670174</td>\n",
       "<td>-73.0298414</td>\n",
       "<td>61.1683682</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000006</td>\n",
       "<td>0.0121167</td>\n",
       "<td>0.1427911</td>\n",
       "<td>1.4018502</td>\n",
       "<td>0.0094947</td>\n",
       "<td>0.0128585</td>\n",
       "<td>0.0932144</td>\n",
       "<td>0.0903001</td>\n",
       "<td>0.0142786</td>\n",
       "<td>0.9812959</td>\n",
       "<td>-85.7208879</td>\n",
       "<td>40.1850210</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999967</td>\n",
       "<td>0.0112748</td>\n",
       "<td>0.0876788</td>\n",
       "<td>1.2375845</td>\n",
       "<td>0.0058301</td>\n",
       "<td>0.0116668</td>\n",
       "<td>0.0822917</td>\n",
       "<td>0.0804712</td>\n",
       "<td>0.0087675</td>\n",
       "<td>0.9900635</td>\n",
       "<td>-91.2321242</td>\n",
       "<td>23.7584479</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999983</td>\n",
       "<td>0.0106105</td>\n",
       "<td>0.0642942</td>\n",
       "<td>1.1072165</td>\n",
       "<td>0.0042752</td>\n",
       "<td>0.0109280</td>\n",
       "<td>0.0736230</td>\n",
       "<td>0.0727441</td>\n",
       "<td>0.0064295</td>\n",
       "<td>0.9964930</td>\n",
       "<td>-93.5705814</td>\n",
       "<td>10.7216478</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0090048</td>\n",
       "<td>0.0350696</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0023319</td>\n",
       "<td>0.0102215</td>\n",
       "<td>0.0664938</td>\n",
       "<td>0.0664917</td>\n",
       "<td>0.0035070</td>\n",
       "<td>1.0</td>\n",
       "<td>-96.4930444</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100052                   0.997919           14.3713    14.3713            0.955605         0.999612   0.955605                    0.999612            0.143788        0.143788                   1337.13   1337.13\n",
       "    2        0.0200048                   0.936624           13.1351    13.7534            0.873404         0.978612   0.914516                    0.989115            0.131346        0.275134                   1213.51   1275.34\n",
       "    3        0.0300044                   0.672178           11.5318    13.013             0.766796         0.818164   0.865285                    0.932142            0.115314        0.390448                   1053.18   1201.3\n",
       "    4        0.040004                    0.39626            9.20209    12.0604            0.611882         0.519589   0.801943                    0.829018            0.0920174       0.482465                   820.209   1106.04\n",
       "    5        0.0500036                   0.258873           7.22306    11.0931            0.480289         0.31712    0.737619                    0.72665             0.0722278       0.554693                   622.306   1009.31\n",
       "    6        0.100002                    0.0997466          3.35851    7.226              0.22332          0.151116   0.480484                    0.438899            0.167919        0.722612                   235.851   622.6\n",
       "    7        0.15                        0.0671994          1.34441    5.26554            0.0893948        0.0810978  0.350126                    0.319636            0.0672178       0.78983                    34.4408   426.554\n",
       "    8        0.200003                    0.0518557          0.73976    4.13403            0.0491894        0.0587943  0.274888                    0.254422            0.0369906       0.82682                    -26.024   313.403\n",
       "    9        0.299999                    0.0358625          0.458435   2.90888            0.0304831        0.0430093  0.193422                    0.183954            0.0458417       0.872662                   -54.1565  190.888\n",
       "    10       0.400001                    0.0253472          0.349861   2.26912            0.0232636        0.0304552  0.150882                    0.145579            0.0349866       0.907649                   -65.0139  126.912\n",
       "    11       0.500003                    0.0179124          0.323976   1.88008            0.0215424        0.0213885  0.125014                    0.12074             0.0323981       0.940047                   -67.6024  88.0083\n",
       "    12       0.600004                    0.0138157          0.269702   1.61168            0.0179335        0.0155379  0.107167                    0.103206            0.0269706       0.967017                   -73.0298  61.1684\n",
       "    13       0.700001                    0.0121167          0.142791   1.40185            0.00949473       0.0128585  0.0932144                   0.0903001           0.0142786       0.981296                   -85.7209  40.185\n",
       "    14       0.799997                    0.0112748          0.0876788  1.23758            0.00583009       0.0116668  0.0822917                   0.0804712           0.00876754      0.990063                   -91.2321  23.7584\n",
       "    15       0.899998                    0.0106105          0.0642942  1.10722            0.00427517       0.010928   0.073623                    0.0727441           0.00642953      0.996493                   -93.5706  10.7216\n",
       "    16       1                           0.00900476         0.0350696  1                  0.00233191       0.0102215  0.0664938                   0.0664917           0.00350701      1                          -96.493   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.07372284008324068\n",
      "RMSE: 0.2715195022152933\n",
      "LogLoss: 0.28710582270564294\n",
      "Null degrees of freedom: 199999\n",
      "Residual degrees of freedom: 199997\n",
      "Null deviance: 92813.47637268194\n",
      "Residual deviance: 114842.32908225719\n",
      "AIC: 114848.32908225719\n",
      "AUC: 0.7145940537294438\n",
      "pr_auc: 0.1388904542988752\n",
      "Gini: 0.4291881074588877\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1033622205246096: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>160680.0</td>\n",
       "<td>26963.0</td>\n",
       "<td>0.1437</td>\n",
       "<td> (26963.0/187643.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>7798.0</td>\n",
       "<td>4559.0</td>\n",
       "<td>0.6311</td>\n",
       "<td> (7798.0/12357.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>168478.0</td>\n",
       "<td>31522.0</td>\n",
       "<td>0.1738</td>\n",
       "<td> (34761.0/200000.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0       1      Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "0      160680  26963  0.1437   (26963.0/187643.0)\n",
       "1      7798    4559   0.6311   (7798.0/12357.0)\n",
       "Total  168478  31522  0.1738   (34761.0/200000.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1033622</td>\n",
       "<td>0.2077987</td>\n",
       "<td>282.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0292257</td>\n",
       "<td>0.3233802</td>\n",
       "<td>365.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9072939</td>\n",
       "<td>0.2301102</td>\n",
       "<td>28.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9998334</td>\n",
       "<td>0.939925</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9998334</td>\n",
       "<td>0.6741344</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0102945</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9998334</td>\n",
       "<td>0.9982946</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.9998334</td>\n",
       "<td>0.1786554</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0433298</td>\n",
       "<td>0.6436028</td>\n",
       "<td>343.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0284777</td>\n",
       "<td>0.6509346</td>\n",
       "<td>366.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.103362     0.207799  282\n",
       "max f2                       0.0292257    0.32338   365\n",
       "max f0point5                 0.907294     0.23011   28\n",
       "max accuracy                 0.999833     0.939925  0\n",
       "max precision                0.999833     0.674134  0\n",
       "max recall                   0.0102945    1         399\n",
       "max specificity              0.999833     0.998295  0\n",
       "max absolute_mcc             0.999833     0.178655  0\n",
       "max min_per_class_accuracy   0.0433298    0.643603  343\n",
       "max mean_per_class_accuracy  0.0284777    0.650935  366"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  6.18 %, avg score:  8.65 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.9866447</td>\n",
       "<td>7.3318767</td>\n",
       "<td>7.3318767</td>\n",
       "<td>0.453</td>\n",
       "<td>0.9971714</td>\n",
       "<td>0.453</td>\n",
       "<td>0.9971714</td>\n",
       "<td>0.0733188</td>\n",
       "<td>0.0733188</td>\n",
       "<td>633.1876669</td>\n",
       "<td>633.1876669</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.020005</td>\n",
       "<td>0.8873566</td>\n",
       "<td>3.1707057</td>\n",
       "<td>5.2507711</td>\n",
       "<td>0.1959020</td>\n",
       "<td>0.9461028</td>\n",
       "<td>0.3244189</td>\n",
       "<td>0.9716307</td>\n",
       "<td>0.0317229</td>\n",
       "<td>0.1050417</td>\n",
       "<td>217.0705656</td>\n",
       "<td>425.0771146</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.7247594</td>\n",
       "<td>2.5666309</td>\n",
       "<td>4.3565051</td>\n",
       "<td>0.1585793</td>\n",
       "<td>0.8059655</td>\n",
       "<td>0.2691667</td>\n",
       "<td>0.9164366</td>\n",
       "<td>0.0256535</td>\n",
       "<td>0.1306952</td>\n",
       "<td>156.6630892</td>\n",
       "<td>335.6505085</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.040005</td>\n",
       "<td>0.5712060</td>\n",
       "<td>1.9169828</td>\n",
       "<td>3.7463958</td>\n",
       "<td>0.1184408</td>\n",
       "<td>0.6453605</td>\n",
       "<td>0.2314711</td>\n",
       "<td>0.8486422</td>\n",
       "<td>0.0191794</td>\n",
       "<td>0.1498746</td>\n",
       "<td>91.6982756</td>\n",
       "<td>274.6395826</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.4318190</td>\n",
       "<td>1.9027074</td>\n",
       "<td>3.3778425</td>\n",
       "<td>0.1175588</td>\n",
       "<td>0.4997319</td>\n",
       "<td>0.2087</td>\n",
       "<td>0.7788950</td>\n",
       "<td>0.0190176</td>\n",
       "<td>0.1688921</td>\n",
       "<td>90.2707443</td>\n",
       "<td>237.7842518</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.1719443</td>\n",
       "<td>1.8985191</td>\n",
       "<td>2.6381808</td>\n",
       "<td>0.1173</td>\n",
       "<td>0.2663726</td>\n",
       "<td>0.163</td>\n",
       "<td>0.5226338</td>\n",
       "<td>0.0949260</td>\n",
       "<td>0.2638181</td>\n",
       "<td>89.8519058</td>\n",
       "<td>163.8180788</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15001</td>\n",
       "<td>0.1084825</td>\n",
       "<td>1.8301754</td>\n",
       "<td>2.3688097</td>\n",
       "<td>0.1130774</td>\n",
       "<td>0.1355429</td>\n",
       "<td>0.1463569</td>\n",
       "<td>0.3935863</td>\n",
       "<td>0.0915271</td>\n",
       "<td>0.3553451</td>\n",
       "<td>83.0175358</td>\n",
       "<td>136.8809736</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0812213</td>\n",
       "<td>1.4440049</td>\n",
       "<td>2.1376548</td>\n",
       "<td>0.0892178</td>\n",
       "<td>0.0930732</td>\n",
       "<td>0.132075</td>\n",
       "<td>0.3184731</td>\n",
       "<td>0.0721858</td>\n",
       "<td>0.4275310</td>\n",
       "<td>44.4004913</td>\n",
       "<td>113.7654771</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.0541062</td>\n",
       "<td>1.3004775</td>\n",
       "<td>1.8585957</td>\n",
       "<td>0.08035</td>\n",
       "<td>0.0658557</td>\n",
       "<td>0.1148333</td>\n",
       "<td>0.2342673</td>\n",
       "<td>0.1300477</td>\n",
       "<td>0.5575787</td>\n",
       "<td>30.0477462</td>\n",
       "<td>85.8595668</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.40043</td>\n",
       "<td>0.0406178</td>\n",
       "<td>1.0918495</td>\n",
       "<td>1.6662916</td>\n",
       "<td>0.0674599</td>\n",
       "<td>0.0463507</td>\n",
       "<td>0.1029518</td>\n",
       "<td>0.1871368</td>\n",
       "<td>0.1096544</td>\n",
       "<td>0.6672331</td>\n",
       "<td>9.1849516</td>\n",
       "<td>66.6291605</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0311737</td>\n",
       "<td>1.1248498</td>\n",
       "<td>1.5584689</td>\n",
       "<td>0.0694988</td>\n",
       "<td>0.0358684</td>\n",
       "<td>0.09629</td>\n",
       "<td>0.1570132</td>\n",
       "<td>0.1120013</td>\n",
       "<td>0.7792344</td>\n",
       "<td>12.4849802</td>\n",
       "<td>55.8468884</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0224028</td>\n",
       "<td>0.9168892</td>\n",
       "<td>1.4515389</td>\n",
       "<td>0.05665</td>\n",
       "<td>0.0266209</td>\n",
       "<td>0.0896833</td>\n",
       "<td>0.1352812</td>\n",
       "<td>0.0916889</td>\n",
       "<td>0.8709234</td>\n",
       "<td>-8.3110787</td>\n",
       "<td>45.1538939</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0152625</td>\n",
       "<td>0.6093712</td>\n",
       "<td>1.3312293</td>\n",
       "<td>0.03765</td>\n",
       "<td>0.0185055</td>\n",
       "<td>0.08225</td>\n",
       "<td>0.1185989</td>\n",
       "<td>0.0609371</td>\n",
       "<td>0.9318605</td>\n",
       "<td>-39.0628793</td>\n",
       "<td>33.1229263</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0119436</td>\n",
       "<td>0.3916808</td>\n",
       "<td>1.2137857</td>\n",
       "<td>0.0242</td>\n",
       "<td>0.0133851</td>\n",
       "<td>0.0749937</td>\n",
       "<td>0.1054472</td>\n",
       "<td>0.0391681</td>\n",
       "<td>0.9710286</td>\n",
       "<td>-60.8319171</td>\n",
       "<td>21.3785709</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.900045</td>\n",
       "<td>0.0107252</td>\n",
       "<td>0.2297259</td>\n",
       "<td>1.1044020</td>\n",
       "<td>0.0141936</td>\n",
       "<td>0.0113381</td>\n",
       "<td>0.0682355</td>\n",
       "<td>0.0949864</td>\n",
       "<td>0.0229829</td>\n",
       "<td>0.9940115</td>\n",
       "<td>-77.0274130</td>\n",
       "<td>10.4401993</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0097144</td>\n",
       "<td>0.0599120</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0037017</td>\n",
       "<td>0.0104066</td>\n",
       "<td>0.061785</td>\n",
       "<td>0.0865323</td>\n",
       "<td>0.0059885</td>\n",
       "<td>1.0</td>\n",
       "<td>-94.0087954</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.01                        0.986645           7.33188   7.33188            0.453            0.997171   0.453                       0.997171            0.0733188       0.0733188                  633.188   633.188\n",
       "    2        0.020005                    0.887357           3.17071   5.25077            0.195902         0.946103   0.324419                    0.971631            0.0317229       0.105042                   217.071   425.077\n",
       "    3        0.03                        0.724759           2.56663   4.35651            0.158579         0.805965   0.269167                    0.916437            0.0256535       0.130695                   156.663   335.651\n",
       "    4        0.040005                    0.571206           1.91698   3.7464             0.118441         0.645361   0.231471                    0.848642            0.0191794       0.149875                   91.6983   274.64\n",
       "    5        0.05                        0.431819           1.90271   3.37784            0.117559         0.499732   0.2087                      0.778895            0.0190176       0.168892                   90.2707   237.784\n",
       "    6        0.1                         0.171944           1.89852   2.63818            0.1173           0.266373   0.163                       0.522634            0.094926        0.263818                   89.8519   163.818\n",
       "    7        0.15001                     0.108482           1.83018   2.36881            0.113077         0.135543   0.146357                    0.393586            0.0915271       0.355345                   83.0175   136.881\n",
       "    8        0.2                         0.0812213          1.444     2.13765            0.0892178        0.0930732  0.132075                    0.318473            0.0721858       0.427531                   44.4005   113.765\n",
       "    9        0.3                         0.0541062          1.30048   1.8586             0.08035          0.0658557  0.114833                    0.234267            0.130048        0.557579                   30.0477   85.8596\n",
       "    10       0.40043                     0.0406178          1.09185   1.66629            0.0674599        0.0463507  0.102952                    0.187137            0.109654        0.667233                   9.18495   66.6292\n",
       "    11       0.5                         0.0311737          1.12485   1.55847            0.0694988        0.0358684  0.09629                     0.157013            0.112001        0.779234                   12.485    55.8469\n",
       "    12       0.6                         0.0224028          0.916889  1.45154            0.05665          0.0266209  0.0896833                   0.135281            0.0916889       0.870923                   -8.31108  45.1539\n",
       "    13       0.7                         0.0152625          0.609371  1.33123            0.03765          0.0185055  0.08225                     0.118599            0.0609371       0.93186                    -39.0629  33.1229\n",
       "    14       0.8                         0.0119436          0.391681  1.21379            0.0242           0.0133851  0.0749937                   0.105447            0.0391681       0.971029                   -60.8319  21.3786\n",
       "    15       0.900045                    0.0107252          0.229726  1.1044             0.0141936        0.0113381  0.0682355                   0.0949864           0.0229829       0.994011                   -77.0274  10.4402\n",
       "    16       1                           0.0097144          0.059912  1                  0.00370167       0.0104066  0.061785                    0.0865323           0.00598851      1                          -94.0088  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_perf = mod_best.model_performance(test_df)\n",
    "mod_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
