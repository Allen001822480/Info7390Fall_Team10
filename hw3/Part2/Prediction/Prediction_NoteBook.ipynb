{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "############### Import Libraries ###############\n",
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from Part2_get_data_prediction import get_data\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "# this allows plots to appear directly in the notebook %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Inputs  ###############\n",
    "'''arg_len=len(sys.argv)quarter=''\n",
    "if arg_len == 1:\n",
    "    quarter = 'Q12005'\n",
    "    print('Running program for Q12005 by default')\n",
    "elif arg_len == 2:\n",
    "    quarter =sys.argv[1]\n",
    "else:\n",
    "    quarter = 'Q12005'\n",
    "    print('Running program for Q12005 by default')'''\n",
    "    \n",
    "quarter = 'Q12005'\n",
    "# get_data(quarter)\n",
    "\n",
    "# Load data into DataFrame\n",
    "col_names_orig=['credit_score', 'first_pay_date', 'first_time_homebuyer',\n",
    "                'maturity_date', 'msa', 'mi_percentage', 'no_of_units','occupance_status',\n",
    "                'original_cltv', 'original_dti_ratio', 'original_upb', 'original_ltv',\n",
    "                'original_interest_rate', 'channel', 'ppm_flag', 'product_type',\n",
    "                'property_state', 'property_type', 'postal_code', 'loan_sequence_no', \n",
    "                'loan_purpose', 'original_loan_term', 'no_of_borrowers', 'seller_name',\n",
    "                'servicer_name', 'super_conforming_flag']\n",
    "\n",
    "df1 = pd.read_table('HistoricalInputFiles/historical_data1_Q12005.txt', delimiter='|', names=col_names_orig)\n",
    "df2 = pd.read_table('HistoricalInputFiles/historical_data1_Q22005.txt', delimiter='|', names=col_names_orig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished cleaning df1\n",
      "Finished cleaning df2\n"
     ]
    }
   ],
   "source": [
    "##################### clean the dataframe and fill missing values #####################\n",
    "def clean_df(df):\n",
    "    # Credit_score\n",
    "    df.credit_score = df.credit_score.replace(r'\\s+', np.nan, regex=True).astype('float64')\n",
    "    max_cs = pd.DataFrame(df['credit_score'])\n",
    "    max_cs = max_cs.mode()\n",
    "    df['credit_score'] = df['credit_score'].fillna(max_cs.iloc[0]['credit_score'])\n",
    "\n",
    "    # First_time_homebuyer\n",
    "    #df.first_time_homebuyer = df.first_time_homebuyer.str.strip()\n",
    "    df.first_time_homebuyer.replace(np.nan, 0, inplace=True)\n",
    "    df.first_time_homebuyer.replace('N', 1, inplace=True)\n",
    "    df.first_time_homebuyer.replace('Y', 2, inplace=True)\n",
    "    df.first_time_homebuyer = df.first_time_homebuyer.astype('category')\n",
    "\n",
    "    # MSA\n",
    "    df.msa = df.msa.replace(np.nan, 0, regex=True).astype('float64')\n",
    "\n",
    "    # mi_percentage\n",
    "    df.mi_percentage = df.mi_percentage.replace(r'\\s+', np.nan, regex=True).astype('float64')\n",
    "    df.mi_percentage.replace(np.nan, df.mi_percentage.mean(), inplace=True)\n",
    "\n",
    "    # no_of_units\n",
    "    df.no_of_units=df.no_of_units.replace(np.nan, 0, regex=True).astype('float64')\n",
    "    df.no_of_units = df.no_of_units.astype('category')\n",
    "    \n",
    "    # occupancy_status\n",
    "    df.occupance_status.replace('', 0, inplace=True)\n",
    "    df.occupance_status.replace('O', 1, inplace=True)\n",
    "    df.occupance_status.replace('S', 2, inplace=True)\n",
    "    df.occupance_status.replace('I', 3, inplace=True)\n",
    "    df.occupance_status = df.occupance_status.astype('category')\n",
    "    \n",
    "    # original_cltv\n",
    "    df.original_cltv.replace(np.nan, df.original_cltv.mean(), inplace=True)\n",
    "\n",
    "    # original_dti_ratio\n",
    "    df.original_dti_ratio = df.original_dti_ratio.replace(r'\\s+', 66, regex=True).astype('float64')\n",
    "    df.original_dti_ratio = df.original_dti_ratio.replace(np.nan, 0).astype('float64')\n",
    "\n",
    "    # original_ltv\n",
    "    df.original_ltv = df.original_ltv.replace(r'\\s+', np.nan, regex=True).astype('float64')\n",
    "    df.original_ltv.replace(np.nan, df.original_ltv.mean(), inplace=True)\n",
    "    df.original_ltv = df.original_ltv.astype('category')\n",
    "    \n",
    "    # Channel\n",
    "    df.channel = df.channel.str.strip()\n",
    "    df.channel.replace('', 0, inplace=True)\n",
    "    df.channel.replace('R', 1, inplace=True)\n",
    "    df.channel.replace('T', 2, inplace=True)\n",
    "    df.channel.replace('C', 3, inplace=True)\n",
    "    df.channel.replace('B', 4, inplace=True)\n",
    "    df.channel = df.channel.astype('category')\n",
    "\n",
    "    # ppm_flag\n",
    "    df.ppm_flag.replace(np.nan, 0, inplace=True)\n",
    "    df.ppm_flag.replace('N', 0, inplace=True)\n",
    "    df.ppm_flag.replace('Y', 1, inplace=True)\n",
    "    df.ppm_flag = df.ppm_flag.astype('category')\n",
    "\n",
    "    # product_type\n",
    "    df.product_type.replace('FRM', 0, inplace=True)\n",
    "\n",
    "    # property_type\n",
    "    df.property_type = df.property_type.str.strip()\n",
    "    df.property_type.replace('', 0, inplace=True)\n",
    "    df.property_type.replace('SF', 1, inplace=True)\n",
    "    df.property_type.replace('CO', 2, inplace=True)\n",
    "    df.property_type.replace('PU', 3, inplace=True)\n",
    "    df.property_type.replace('MH', 4, inplace=True)\n",
    "    df.property_type.replace('LH', 5, inplace=True)\n",
    "    df.property_type.replace('CP', 6, inplace=True)\n",
    "    df.property_type = df.property_type.astype('category')\n",
    "\n",
    "    # postal_code\n",
    "    df.postal_code = df.postal_code.replace(np.nan, 0, regex=True).astype('float64')\n",
    "\n",
    "    # loan_purpose\n",
    "    df.loan_purpose = df.loan_purpose.str.strip()\n",
    "    df.loan_purpose.replace('', 0, inplace=True)\n",
    "    df.loan_purpose.replace('C', 1, inplace=True)\n",
    "    df.loan_purpose.replace('N', 2, inplace=True)\n",
    "    df.loan_purpose.replace('P', 3, inplace=True)\n",
    "    df.loan_purpose = df.loan_purpose.astype('category')\n",
    "\n",
    "    # no_of_borrowers\n",
    "    df.no_of_borrowers=df.no_of_borrowers.replace(r'\\s+', np.nan, regex=True).astype('float64')\n",
    "    df.no_of_borrowers = df.no_of_borrowers.replace(r'\\s+', np.nan, regex=True).astype('float64')\n",
    "    max_b = pd.DataFrame(df['no_of_borrowers'])\n",
    "    max_b = max_b.mode()\n",
    "    df['no_of_borrowers'] = df['no_of_borrowers'].fillna(max_b.iloc[0]['no_of_borrowers'])\n",
    "\n",
    "    #super_conforming_flag\n",
    "    df.super_conforming_flag=df.super_conforming_flag.replace(r'\\s+', np.nan, regex=True).astype('float64')\n",
    "\n",
    "\n",
    "clean_df(df1)\n",
    "print('Finished cleaning df1')\n",
    "clean_df(df2)\n",
    "print('Finished cleaning df2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Features and Labels #######################\n",
    "X_train_org = df1.drop(['original_interest_rate',\n",
    "             'property_state', \n",
    "             'loan_sequence_no', \n",
    "             'seller_name', 'servicer_name', 'super_conforming_flag', 'occupance_status'], axis=1)\n",
    "y_train = df1['original_interest_rate']\n",
    "\n",
    "X_test_org = df2.drop(['original_interest_rate',\n",
    "             'property_state', \n",
    "             'loan_sequence_no', \n",
    "             'seller_name', 'servicer_name', 'super_conforming_flag', 'occupance_status'], axis=1)\n",
    "y_test = df2['original_interest_rate']\n",
    "\n",
    "'''X_train = preprocessing.minmax_scale(X_train_org) # scale between 0 and 1\n",
    "X_test = preprocessing.minmax_scale(X_test_org)'''\n",
    "\n",
    "\n",
    "X_train = X_train_org\n",
    "X_test = X_test_org\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Build Regression Model #######################\n",
    "# Scaling all the features\n",
    "#X = preprocessing.scale(X)\n",
    "\n",
    "error_metric = pd.DataFrame({'rms_train':[], \n",
    "                             'rms_test': [],\n",
    "                             'mae_train': [],\n",
    "                             'mae_test':[],\n",
    "                             'mape_train':[],\n",
    "                             'mape_test':[]})\n",
    "\n",
    "rmse_dict = {}    \n",
    "    \n",
    "def calc_error_metric(modelname, model, X_train, y_train, X_test, y_test):\n",
    "    global error_metric\n",
    "    y_train_predicted = model.predict(X_train)\n",
    "    y_test_predicted = model.predict(X_test)\n",
    "    \n",
    "    #MAE, RMS, MAPE\n",
    "    rms_train = mean_squared_error(y_train, y_train_predicted)\n",
    "    rms_test = mean_squared_error(y_test, y_test_predicted)\n",
    "    \n",
    "    mae_train = mean_absolute_error(y_train, y_train_predicted)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_predicted)\n",
    "    \n",
    "    mape_train = np.mean(np.abs((y_train - y_train_predicted) / y_train)) * 100\n",
    "    mape_test = np.mean(np.abs((y_test - y_test_predicted) / y_test)) * 100\n",
    "    \n",
    "    rmse_dict[modelname] = rms_test\n",
    "    \n",
    "    df_local = pd.DataFrame({'Model':[modelname],\n",
    "                             'rms_train':[rms_train], \n",
    "                             'rms_test': [rms_test],\n",
    "                             'mae_train': [mae_train],\n",
    "                             'mae_test':[mae_test],\n",
    "                             'mape_train':[mape_train],\n",
    "                             'mape_test':[mape_test]})\n",
    "    \n",
    "    error_metric = pd.concat([error_metric, df_local])\n",
    "    return error_metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest completed\n",
      "KNN completed\n",
      "Nueral Network completed\n",
      "Best Model is  RandomForest\n"
     ]
    }
   ],
   "source": [
    "# Regression\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "calc_error_metric('Regression', clf, X_train, y_train, X_test, y_test)\n",
    "print('Regression completed')\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=20)\n",
    "rf.fit(X_train, y_train)\n",
    "calc_error_metric('RandomForest', rf, X_train, y_train, X_test, y_test)\n",
    "print('RandomForest completed')\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsRegressor(n_neighbors=13)\n",
    "knn.fit(X_train_org, y_train)\n",
    "calc_error_metric('KNN', knn, X_train, y_train, X_test, y_test)\n",
    "print('KNN completed')\n",
    "\n",
    "# Neural network\n",
    "nn = MLPRegressor()\n",
    "nn.fit(X_train, y_train)\n",
    "calc_error_metric('Nueral Network', nn, X_train_org, y_train, X_test_org, y_test)\n",
    "print('Nueral Network completed')\n",
    "\n",
    "#### Calculate best model\n",
    "best_model =  min(rmse_dict.items(),key=operator.itemgetter(1))[0]\n",
    "print('Best Model is ', best_model)\n",
    "\n",
    "#### Write the error\n",
    "error_metric.to_csv('Error_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
